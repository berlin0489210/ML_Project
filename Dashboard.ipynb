{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dashboard Implementation\n",
        "---\n",
        "\n",
        "100489210 | Xin Ying Leong \\\n",
        "100496657 | Adeline Poncet \\\n",
        "100496636 | Blanca Sánchez"
      ],
      "metadata": {
        "id": "i6bLUCD7za1h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "af06HPmhODr_",
        "outputId": "a7478a71-5f75-4228-eb40-7ac17d04cc14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m155.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Collecting dash\n",
            "  Downloading dash-3.0.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting Flask<3.1,>=1.0.4 (from dash)\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting Werkzeug<3.1 (from dash)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash) (8.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash) (4.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dash) (2.32.3)\n",
            "Collecting retrying (from dash)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash) (75.2.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Werkzeug<3.1->dash) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from retrying->dash) (1.17.0)\n",
            "Downloading dash-3.0.4-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: Werkzeug, retrying, Flask, dash\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 3.1.0\n",
            "    Uninstalling Flask-3.1.0:\n",
            "      Successfully uninstalled Flask-3.1.0\n",
            "Successfully installed Flask-3.0.3 Werkzeug-3.0.6 dash-3.0.4 retrying-1.3.4\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n",
            "Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-2.0 pyLDAvis-3.4.1\n",
            "Collecting dash-bootstrap-components\n",
            "  Downloading dash_bootstrap_components-2.0.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: dash>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from dash-bootstrap-components) (3.0.4)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from dash>=3.0.3->dash-bootstrap-components) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.11/dist-packages (from dash>=3.0.3->dash-bootstrap-components) (3.0.6)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash>=3.0.3->dash-bootstrap-components) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash>=3.0.3->dash-bootstrap-components) (8.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash>=3.0.3->dash-bootstrap-components) (4.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dash>=3.0.3->dash-bootstrap-components) (2.32.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash>=3.0.3->dash-bootstrap-components) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=3.0.3->dash-bootstrap-components) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash>=3.0.3->dash-bootstrap-components) (75.2.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=3.0.3->dash-bootstrap-components) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=3.0.3->dash-bootstrap-components) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=3.0.3->dash-bootstrap-components) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=3.0.3->dash-bootstrap-components) (1.9.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash>=3.0.3->dash-bootstrap-components) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash>=3.0.3->dash-bootstrap-components) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Werkzeug<3.1->dash>=3.0.3->dash-bootstrap-components) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash>=3.0.3->dash-bootstrap-components) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=3.0.3->dash-bootstrap-components) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=3.0.3->dash-bootstrap-components) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=3.0.3->dash-bootstrap-components) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=3.0.3->dash-bootstrap-components) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from retrying->dash>=3.0.3->dash-bootstrap-components) (1.17.0)\n",
            "Downloading dash_bootstrap_components-2.0.2-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dash-bootstrap-components\n",
            "Successfully installed dash-bootstrap-components-2.0.2\n",
            "Collecting compress_fasttext\n",
            "  Downloading compress-fasttext-0.1.5.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from compress_fasttext) (4.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from compress_fasttext) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim>=4.0.0->compress_fasttext) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim>=4.0.0->compress_fasttext) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim>=4.0.0->compress_fasttext) (1.17.2)\n",
            "Building wheels for collected packages: compress_fasttext\n",
            "  Building wheel for compress_fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compress_fasttext: filename=compress_fasttext-0.1.5-py3-none-any.whl size=16098 sha256=2e8bb2829cdf76522a596f392f61e3293265ac19a841ec02d4b8208e9bb1b599\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/ed/77/0a7fc5e08ff30e062f09c6904844a5911a9e30a7e5ec376890\n",
            "Successfully built compress_fasttext\n",
            "Installing collected packages: compress_fasttext\n",
            "Successfully installed compress_fasttext-0.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install --no-cache-dir --upgrade numpy scipy gensim\n",
        "!pip install --no-cache-dir pandas==2.2.2\n",
        "!pip install dash\n",
        "!pip install pyLDAvis\n",
        "!pip install dash-bootstrap-components\n",
        "!pip install compress_fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCpWCMJ8NxdM",
        "outputId": "a6594034-8c4e-4a7a-ed7c-6ab0a9eaf199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "folder_path= ('/content/drive/MyDrive/ML Applications/recipes/')\n",
        "# folder_path= ('/content/drive/MyDrive/recipes/')\n",
        "# folder_path = \"/content/drive/My Drive/MLA Project/recipes\"\n",
        "folder_path = \"/content/drive/My Drive/3º uni/Machine Learning Applications/recipes/\"\n",
        "os.chdir(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXf1KLu5S6_X"
      },
      "outputs": [],
      "source": [
        "from dash import Dash, html, dcc, callback_context, no_update\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.corpora import Dictionary, MmCorpus\n",
        "import tempfile\n",
        "import os\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import dash_bootstrap_components as dbc\n",
        "from dash.dependencies import Input, Output, State, ALL, MATCH\n",
        "import ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5qIXu3kaMTL"
      },
      "source": [
        "#### Page 1 LDA Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mV0rJTkNV99"
      },
      "outputs": [],
      "source": [
        "# Load model and data\n",
        "ldag = LdaModel.load(\"lda_recipe_grouped_reviews.gensim\")\n",
        "num_topics = ldag.num_topics\n",
        "corpus_bow_recipes = MmCorpus(\"recipes_bow.mm\")\n",
        "D_recipes = Dictionary.load(\"recipes_dictionary.dict\")\n",
        "\n",
        "# LDA visual\n",
        "vis_data = gensimvis.prepare(ldag, corpus_bow_recipes, D_recipes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ab0H96oslRuW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "grouped_reviews_df = pd.read_csv(\"recipe_reviews_grouped.csv\")\n",
        "recipes_df = pd.read_csv('recipe_df.csv')\n",
        "relevant_allRecipes_html = {}\n",
        "\n",
        "def get_relevant_topics(topicid):\n",
        "    # Create list to return\n",
        "    most_relevant_recipes = []\n",
        "    items = [word for word, weight in ldag.show_topic(topicid)]\n",
        "\n",
        "    # Compute topic weight for each document and sort by relevance\n",
        "    sorted_docs = sorted(\n",
        "        ((i, dict(ldag[doc]).get(topicid, 0)) for i, doc in enumerate(corpus_bow_recipes)),\n",
        "        key=lambda x: x[1],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    # Extract top document IDs\n",
        "    most_relevant_recipes = [doc_id for doc_id, _ in sorted_docs[:10]]\n",
        "    return most_relevant_recipes\n",
        "\n",
        "def get_recipe_name_cuisine(recipe_ids):\n",
        "    top_5 = []\n",
        "    for id in recipe_ids:\n",
        "        recipe_id = grouped_reviews_df.iloc[id]['recipe_id']\n",
        "        title= grouped_reviews_df[grouped_reviews_df['recipe_id'] == recipe_id]['recipe'].values[0]\n",
        "        cuisine= recipes_df[recipes_df['recipe_id'] == recipe_id]['Cuisine'].values[0]\n",
        "        top_5.append((title, cuisine))\n",
        "    return top_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRvgJHg5eUKk"
      },
      "outputs": [],
      "source": [
        "for key in range(num_topics):\n",
        "    rel_recipes_ids = get_relevant_topics(key)\n",
        "    rel_recipes = get_recipe_name_cuisine(rel_recipes_ids)\n",
        "    rel_recipes_html = [html.P(f\"{title} - {cuisine}\", className=\"card-text\") for i, (title, cuisine) in enumerate(rel_recipes)]\n",
        "    relevant_allRecipes_html[key] = rel_recipes_html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug5WTZZ4hEZO"
      },
      "outputs": [],
      "source": [
        "# Save the HTML to a temporary file\n",
        "with tempfile.NamedTemporaryFile(delete=False, suffix=\".html\", mode=\"w+\", encoding=\"utf-8\") as tmp:\n",
        "    pyLDAvis.save_html(vis_data, tmp.name)\n",
        "    tmp_html_path = tmp.name\n",
        "\n",
        "# Read the HTML content\n",
        "with open(tmp_html_path, 'r', encoding='utf-8') as f:\n",
        "    html_content = f\"\"\"<html><head><style>\n",
        "                            html, body {{\n",
        "                                margin: 0;\n",
        "                                padding: 0;\n",
        "                                overflow: hidden;\n",
        "                                height: 100vh;\n",
        "                            }}\n",
        "                            .scaled-wrapper {{\n",
        "                                transform: scale(0.7);\n",
        "                                transform-origin: top left;\n",
        "                                width: calc(100% / 0.7);\n",
        "                                height: calc(100% / 0.7);\n",
        "                            }}\n",
        "                        </style></head><body><div class=\"scaled-wrapper\">{f.read()}</div></body></html>\"\"\"\n",
        "\n",
        "# Clean up the temp file\n",
        "os.unlink(tmp_html_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9JpZ6TAmcZp"
      },
      "outputs": [],
      "source": [
        "tab1 = dbc.Row(\n",
        "[\n",
        "    dbc.Col([\n",
        "        html.Div(children=[\n",
        "                html.Iframe(\n",
        "                    srcDoc=html_content,\n",
        "                    style={\"width\": \"838px\", \"height\": \"544px\", \"border\": \"none\"}\n",
        "                )\n",
        "            ], id = \"lda_vis\", style={\n",
        "                \"display\": \"inline-block\",\n",
        "                \"width\": \"fit-content\"\n",
        "            })\n",
        "    ]),\n",
        "    dbc.Col([\n",
        "        dbc.Stack(['Relevant recipes for ',\n",
        "                    dbc.DropdownMenu(\n",
        "                    label=\"choose topic\",\n",
        "                    size=\"sm\",\n",
        "                    children=[dbc.DropdownMenuItem(f\"Topic {i+1}\", id=f\"relevant-topic-{i+1}\", style={\"fontSize\": \"0.7rem\"}, n_clicks=0) for i in range(num_topics)],\n",
        "                    style={\"display\": \"inline-block\", \"margin-right\": \"10px\", \"font-size\": \"0.7rem\"},\n",
        "                    id=\"relevant-recipes-dd\"\n",
        "        )], direction='horizontal', gap=3),\n",
        "        html.Hr(),\n",
        "        dbc.Card([\n",
        "                dbc.CardHeader(\"Results\"),\n",
        "                dbc.CardBody(id=\"relevant-recipes-results\"),\n",
        "            ],\n",
        "            style={\"width\": \"100%\"},\n",
        "            id=\"relevant-recipes-card\"\n",
        "        )\n",
        "    ], style={\"fontSize\": \"0.8rem\"})\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10rkeHAq4Wki"
      },
      "source": [
        "#### Page 2 Embedding Space Visualization\n",
        "\n",
        "Things to take note of: this tab in the dashboard takes a while to load, so please be patient and avoid excessive clicking on the same button."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdKDT5f84cMq"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "g_fasttext_wv = KeyedVectors.load(\"model_fastText_grouped.wordvectors\", mmap='r')\n",
        "allWords = list(g_fasttext_wv.index_to_key)\n",
        "vectors = np.array([g_fasttext_wv[word] for word in allWords])\n",
        "pca = PCA(n_components=3)\n",
        "reduced = pca.fit_transform(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEnfLj-Jp9Rp"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('grouped_ngrams.pkl', 'rb') as f:\n",
        "    grouped_ngrams = pickle.load(f)\n",
        "\n",
        "ngram_vecs = np.array([g_fasttext_wv[ngram] for ngram in grouped_ngrams])\n",
        "ngram_red = pca.transform(ngram_vecs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhIiOaYJ6nnP"
      },
      "outputs": [],
      "source": [
        "tab2 = dbc.Row([\n",
        "    dbc.Col([\n",
        "        dcc.Graph(\n",
        "        id='3d-word-vectors',\n",
        "        figure=go.Figure(),  # The interactive 3D plot\n",
        "        style={'height': '80vh'}  # Make sure the plot is sufficiently large\n",
        "    )\n",
        "    ], width=8),\n",
        "    dbc.Col([\n",
        "        dbc.Card([\n",
        "            dbc.CardHeader('Look for similar words'),\n",
        "            dbc.CardBody([\n",
        "                dbc.InputGroup([\n",
        "                    dbc.Input(id=\"textbox-similar-vec\", placeholder=\"Search similar words\"),\n",
        "                    dbc.Button(\"Find similar\", id=\"btn-similar-vec\", n_clicks=0),\n",
        "                ], size=\"sm\")\n",
        "            ])\n",
        "        ], class_name=\"mb-2\"),\n",
        "        dbc.Stack([\n",
        "            'Corpus Ngrams',\n",
        "            dbc.Button(\"Show\", id=\"ngram-btn-show\", n_clicks=0, size='sm', style={\"fontSize\": \"0.8rem\"}, color='success')\n",
        "        ], class_name=\"mb-2\", direction=\"horizontal\", gap=2),\n",
        "        dbc.Card([\n",
        "            dbc.CardHeader('Word analogies'),\n",
        "            dbc.CardBody([\n",
        "                dbc.Col([\n",
        "                    'Positive terms',\n",
        "                    dbc.InputGroup([\n",
        "                        dbc.Input(id=\"textbox-word-pos-default\", placeholder=\"Positive word\"),\n",
        "                        dbc.Button(\"+\", id={'type': 'add-button', 'group': 'pos'})\n",
        "                    ], size=\"sm\", class_name=\"mt-1\"),\n",
        "                    html.Div(id={'type': 'words-container', 'group': 'pos'}),\n",
        "                    dcc.Store(id={'type': 'ids', 'group': 'pos'}, data=[])\n",
        "                ], class_name=\"mb-2\"),\n",
        "                dbc.Col([\n",
        "                    'Negative terms',\n",
        "                    dbc.InputGroup([\n",
        "                        dbc.Input(id=\"textbox-word-neg-default\", placeholder=\"Negative word\"),\n",
        "                        dbc.Button(\"+\", id={'type': 'add-button', 'group': 'neg'})\n",
        "                    ], size=\"sm\", class_name=\"mt-1\"),\n",
        "                    html.Div(id={'type': 'words-container', 'group': 'neg'}),\n",
        "                    dcc.Store(id={'type': 'ids', 'group': 'neg'}, data=[])\n",
        "                ], class_name=\"mb-2\")\n",
        "            ]),\n",
        "            dbc.CardFooter([\n",
        "                    dbc.Button(\"Compute\", id=\"compute-btn\", size='sm', style={\"fontSize\": \"0.8rem\"}, color='warning')\n",
        "            ], style={\"display\": \"flex\", \"justifyContent\": \"flex-end\"})\n",
        "        ])\n",
        "    ], style={\"fontSize\": \"0.8rem\"})\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8diNMd-sOwS"
      },
      "source": [
        "#### Page 3 Recommender System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66HyQHACxHX3"
      },
      "outputs": [],
      "source": [
        "reviews_df = pd.read_csv('recipe_reviews_embeddings.csv')\n",
        "reviews_df['embedding'] = reviews_df['embedding'].apply(ast.literal_eval)\n",
        "grouped_reviews_df = pd.read_csv('recipes_embeddings.csv')\n",
        "grouped_reviews_df['embedding'] = grouped_reviews_df['embedding'].apply(ast.literal_eval)\n",
        "grouped_reviews_df = grouped_reviews_df[['recipe_id', 'recipe', 'filtered_nltk_lemmas', 'embedding']]\n",
        "grouped_reviews_df = grouped_reviews_df.drop_duplicates(subset='recipe', keep='first')\n",
        "\n",
        "min_reviews = 5\n",
        "recipes_min_reviews = reviews_df['recipe_id'].value_counts()\n",
        "recipes_min_reviews = recipes_min_reviews[recipes_min_reviews >= min_reviews].index\n",
        "filtered_recipe_df = grouped_reviews_df[grouped_reviews_df['recipe_id'].isin(recipes_min_reviews)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsU7KNbBh8zZ",
        "outputId": "162bbc97-7a26-49f1-95fb-1b376e31c5ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['recipe_id', 'recipe', 'filtered_nltk_lemmas', 'embedding'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "filtered_recipe_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Y8gzKC932CfJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_matrix = cosine_similarity(list(filtered_recipe_df['embedding']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67w1Hc7k-COj"
      },
      "outputs": [],
      "source": [
        "with open(\"Top_50.pkl\", 'rb') as f:\n",
        "    top_50 = pickle.load(f)\n",
        "\n",
        "top_15 = top_50.iloc[:15]\n",
        "most_pop = top_15['Title'].values.tolist()\n",
        "recipe_id_to_index = {r_id: idx for idx, r_id in enumerate(filtered_recipe_df['recipe_id'])}\n",
        "index_to_recipe_id = {idx: r_id for r_id, idx in recipe_id_to_index.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD6wBJtkt8Aq"
      },
      "outputs": [],
      "source": [
        "tab3 = dbc.Row([\n",
        "    dbc.Col([\n",
        "        html.Div(\"Select some dishes you may like:\"),\n",
        "        html.Hr(),\n",
        "        dbc.Checklist(\n",
        "            options=[{'label': recipe, 'value': recipe} for recipe in most_pop],\n",
        "            id='most-pop-list',\n",
        "            inline=False\n",
        "        ),\n",
        "        html.Div(\n",
        "            dbc.Button(\"Get recommendations\", id='recommend-btn', color='primary', className='mt-2', size='sm'), style={\"display\": \"flex\", \"justifyContent\": \"flex-end\"}\n",
        "        )\n",
        "    ], width=5),\n",
        "    dbc.Col([html.Div(style={'borderLeft': '1px solid #ccc', 'height': '100%', 'margin': '0 10px'})], style={\"maxWidth\": \"20px\", \"padding\": \"0\"}, width=\"auto\"),\n",
        "    dbc.Col([\n",
        "        'Based on your selection, we have some recommendations.',\n",
        "        html.Hr(),\n",
        "        html.Ul(id='recommend-out')\n",
        "    ])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHIgxu3laF17"
      },
      "source": [
        "## Main code to deploy the dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "8xFPkRx8aFJz",
        "outputId": "80cbbc73-4890-44e2-b55c-caf40d823eb7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create Dash app\n",
        "app = Dash(external_stylesheets=[dbc.themes.BOOTSTRAP], suppress_callback_exceptions=True)\n",
        "app.title = \"Dashboard\"\n",
        "\n",
        "tabs = {'tab-1': tab1, 'tab-2': tab2, 'tab-3': tab3}\n",
        "\n",
        "# main dashboard layout\n",
        "app.layout = html.Div([\n",
        "    dbc.Card([\n",
        "        dbc.CardHeader(\n",
        "            dbc.Tabs(\n",
        "                [\n",
        "                    dbc.Tab(label=\"LDA Topics\", tab_id=\"tab-1\"),\n",
        "                    dbc.Tab(label=\"Embedding Space\", tab_id=\"tab-2\"),\n",
        "                    dbc.Tab(label=\"Recommender System\", tab_id=\"tab-3\"),\n",
        "                ],\n",
        "                id=\"card-tabs\",\n",
        "                active_tab=\"tab-1\",\n",
        "            )\n",
        "        ),\n",
        "        dbc.CardBody(id=\"card-content\"),\n",
        "    ])\n",
        "], style={\"width\": \"100%\", \"height\": \"100vh\", \"fontSize\": \"0.8rem\"})\n",
        "\n",
        "# callback functions\n",
        "@app.callback(Output(\"card-content\", \"children\"), [Input(\"card-tabs\", \"active_tab\")])\n",
        "def tab_content(active_tab):\n",
        "    return tabs[active_tab]\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"relevant-recipes-dd\", \"label\"),\n",
        "    [Output(f\"relevant-topic-{i+1}\", \"n_clicks\") for i in range(num_topics)],\n",
        "    Output(\"relevant-recipes-results\", \"children\"),\n",
        "    [Input(f\"relevant-topic-{i+1}\", \"n_clicks\") for i in range(num_topics)]\n",
        ")\n",
        "def update_dropdown_label(*args):\n",
        "    if not callback_context.triggered:\n",
        "        return \"choose topic\", *[0]*len(args), \"\"\n",
        "\n",
        "    # Get the ID of the triggered dropdown item\n",
        "    triggered_id = callback_context.triggered[0][\"prop_id\"].split(\".\")[0]\n",
        "\n",
        "    # Extract topic index from ID\n",
        "    if \"relevant-topic-\" in triggered_id:\n",
        "        topic_num = int(triggered_id.split(\"-\")[-1]) - 1\n",
        "    else:\n",
        "        topic_num = 0  # default fallback\n",
        "\n",
        "    selected_label = f\"Topic {topic_num + 1}\"\n",
        "    reset_n_clicks = [0] * len(args)\n",
        "\n",
        "    return selected_label, *reset_n_clicks, relevant_allRecipes_html[topic_num]\n",
        "\n",
        "@app.callback(\n",
        "    Output('3d-word-vectors', 'figure'),\n",
        "    [Input('btn-similar-vec', 'n_clicks'),\n",
        "     Input('ngram-btn-show', 'n_clicks'),\n",
        "     Input('compute-btn', 'n_clicks')],\n",
        "    [State('textbox-similar-vec', 'value'),\n",
        "     State('textbox-word-pos-default', 'value'),\n",
        "    State('textbox-word-neg-default', 'value'),\n",
        "     State({'type': 'input', 'group': 'pos', 'index': ALL}, 'value'),\n",
        "     State({'type': 'input', 'group': 'neg', 'index': ALL}, 'value')],\n",
        "    # prevent_initial_call=True\n",
        ")\n",
        "def unified_callback(n_clicks_similar, n_clicks_ngram, n_clicks_compute, input_word, pos_default, neg_default, pos_values, neg_values):\n",
        "    trigger = callback_context.triggered_id  # Determine which button was clicked\n",
        "    pos_values = [w for w in ([pos_default] + pos_values) if w]\n",
        "    neg_values = [w for w in ([neg_default] + neg_values) if w]\n",
        "\n",
        "    if trigger == 'btn-similar-vec' and input_word:\n",
        "        similar_words = g_fasttext_wv.most_similar(input_word, topn=50)\n",
        "        words = [input_word] + [word for word, _ in similar_words]\n",
        "        vectors = [g_fasttext_wv[word] for word in words]\n",
        "        reduced_vectors = pca.transform(vectors)\n",
        "        plot_title = f\"50 similar words to {input_word}\"\n",
        "        colors = \"blue\"\n",
        "\n",
        "    elif trigger == 'ngram-btn-show':\n",
        "        words = grouped_ngrams\n",
        "        reduced_vectors = ngram_red\n",
        "        plot_title = \"Showing all Ngrams\"\n",
        "        colors = \"blue\"\n",
        "\n",
        "    elif trigger == 'compute-btn' and (pos_values or neg_values):\n",
        "        result_word, similarity = g_fasttext_wv.most_similar(positive = pos_values, negative = neg_values, topn = 1)[0]\n",
        "        words = pos_values + neg_values + [result_word]\n",
        "        total_vectors = [g_fasttext_wv[word] for word in words]\n",
        "        reduced_vectors = pca.transform(total_vectors)\n",
        "        plot_title = f\"{' + '.join(pos_values)} - {' - '.join(neg_values)} ≈ {result_word}\"\n",
        "        colors = ['red' if word == result_word else 'blue' for word in words]\n",
        "\n",
        "    else:\n",
        "        subset_indices = np.random.choice(len(allWords), size=300, replace=False)\n",
        "        words = [allWords[i] for i in subset_indices]\n",
        "        vectors = [g_fasttext_wv[word] for word in words]\n",
        "        reduced_vectors = pca.transform(vectors)\n",
        "        plot_title = \"Showing 300 randomly selected embeddings\"\n",
        "        colors = \"blue\"\n",
        "\n",
        "    # 3D plot\n",
        "    x, y, z = reduced_vectors[:, 0], reduced_vectors[:, 1], reduced_vectors[:, 2]\n",
        "    trace = go.Scatter3d(\n",
        "        x=x, y=y, z=z,\n",
        "        mode='markers+text',\n",
        "        marker=dict(size=5, color=colors, opacity=0.6),\n",
        "        text=words,\n",
        "        textposition=\"top center\",\n",
        "    )\n",
        "\n",
        "    if trigger == 'compute-btn' and (pos_values or neg_values):\n",
        "        result_x, result_y, result_z = reduced_vectors[-1]\n",
        "        line_segments = [\n",
        "            go.Scatter3d(\n",
        "                x=[reduced_vectors[i, 0], result_x],\n",
        "                y=[reduced_vectors[i, 1], result_y],\n",
        "                z=[reduced_vectors[i, 2], result_z],\n",
        "                mode='lines',\n",
        "                line=dict(color='gray', width=2),\n",
        "                showlegend=False\n",
        "            )\n",
        "            for i in range(len(words) - 1)\n",
        "        ]\n",
        "        data = [trace] + line_segments\n",
        "    else:\n",
        "        data = [trace]\n",
        "\n",
        "    layout = go.Layout(\n",
        "        title=plot_title,\n",
        "        scene=dict(\n",
        "            xaxis_title='PC1',\n",
        "            yaxis_title='PC2',\n",
        "            zaxis_title='PC3'\n",
        "        ),\n",
        "        margin=dict(l=0, r=0, b=0, t=40),\n",
        "        dragmode='orbit'\n",
        "    )\n",
        "\n",
        "    return go.Figure(data=data, layout=layout)\n",
        "\n",
        "@app.callback(\n",
        "    Output({'type': 'words-container', 'group': MATCH}, 'children'),\n",
        "    Output({'type': 'ids', 'group': MATCH}, 'data'),\n",
        "    Input({'type': 'add-button', 'group': MATCH}, 'n_clicks'),\n",
        "    State({'type': 'ids', 'group': MATCH}, 'data'),\n",
        "    prevent_initial_call=True\n",
        ")\n",
        "def add_input(n_clicks, ids):\n",
        "    if len(ids) >= 3:\n",
        "        return no_update, no_update\n",
        "    new_id = str(uuid.uuid4())\n",
        "    ids.append(new_id)\n",
        "    group = callback_context.triggered_id['group']\n",
        "    return [generate_input_group(group, i) for i in ids], ids\n",
        "\n",
        "def generate_input_group(group, uid):\n",
        "    ph_text = \"Positive word\" if group == \"pos\" else \"Negative word\"\n",
        "    return dbc.InputGroup([\n",
        "        dbc.Input(id={'type': 'input', 'group': group, 'index': uid}, placeholder=ph_text, size=\"sm\"),\n",
        "        dbc.Button(\"-\", id={'type': 'remove-button', 'group': group, 'index': uid}, size=\"sm\", color=\"danger\")\n",
        "    ], class_name=\"mt-1\", id={'type': 'group', 'group': group, 'index': uid})\n",
        "\n",
        "@app.callback(\n",
        "    Output({'type': 'words-container', 'group': MATCH}, 'children', allow_duplicate=True),\n",
        "    Output({'type': 'ids', 'group': MATCH}, 'data', allow_duplicate=True),\n",
        "    Input({'type': 'remove-button', 'group': MATCH, 'index': ALL}, 'n_clicks'),\n",
        "    State({'type': 'ids', 'group': MATCH}, 'data'),\n",
        "    prevent_initial_call='initial_duplicate'\n",
        ")\n",
        "def remove_input(n_clicks_list, ids):\n",
        "    triggered = callback_context.triggered_id\n",
        "    if not triggered or 'index' not in triggered:\n",
        "        return no_update, no_update\n",
        "\n",
        "    triggered_index = triggered['index']\n",
        "    if triggered_index in ids:\n",
        "        idx = ids.index(triggered_index)\n",
        "        n_clicks = n_clicks_list[idx]\n",
        "        if isinstance(n_clicks, int) and n_clicks > 0:\n",
        "            updated_ids = [uid for uid in ids if uid != triggered_index]\n",
        "            group = triggered['group']\n",
        "            return [generate_input_group(group, i) for i in updated_ids], updated_ids\n",
        "\n",
        "    return no_update, no_update\n",
        "\n",
        "@app.callback(\n",
        "    Output('recommend-out', 'children'),\n",
        "    Input('recommend-btn', 'n_clicks'),\n",
        "    State('most-pop-list', 'value'),\n",
        "    prevent_initial_call=True\n",
        ")\n",
        "def generate_recommendations(n_clicks, selected):\n",
        "    recipes_liked = top_15[top_15[\"Title\"].isin(selected)][\"recipe_id\"].tolist()\n",
        "    result_content = []\n",
        "\n",
        "    for recipe_id in recipes_liked:\n",
        "        if recipe_id not in recipe_id_to_index:\n",
        "            continue\n",
        "\n",
        "        idx = recipe_id_to_index[recipe_id]\n",
        "\n",
        "        title = filtered_recipe_df.loc[filtered_recipe_df['recipe_id'] == recipe_id, 'recipe'].values[0]\n",
        "        similar_indices = np.argsort(similarity_matrix[idx])[::-1]\n",
        "        similar_indices = [i for i in similar_indices if i != idx][:3]\n",
        "\n",
        "        for sim_idx in similar_indices:\n",
        "            similar_recipe_id = index_to_recipe_id[sim_idx]\n",
        "            similar_title = filtered_recipe_df.loc[filtered_recipe_df['recipe_id'] == similar_recipe_id, 'recipe'].values[0]\n",
        "            sim_score = similarity_matrix[idx][sim_idx]\n",
        "            result_content.append(html.Li(similar_title))\n",
        "    return result_content\n",
        "\n",
        "\n",
        "# Run the app\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}